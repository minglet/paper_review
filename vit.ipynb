{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from einops import rearrange, reduce, repeat # einops 직관적으로 사용할 수 있는 차원관리 package\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project input to Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([8, 3, 224, 224])\n",
      "patches: torch.Size([8, 196, 768])\n"
     ]
    }
   ],
   "source": [
    "# input\n",
    "x = torch.randn(8, 3, 224, 224) # (batch_size, channel, height, width)\n",
    "print(f'x: {x.shape}')\n",
    "\n",
    "# b c (h s1) (w s2) # height, width를 각각 patch_size로 나누라는 말\n",
    "# b (h w) (s1 s2 c) # batch_size는 그대로 두고 h*w로 펼쳐서 1차원으로 만들고(14*14=196) s1*s2*3을 펼쳐서 (16*16*3)이 된다. \n",
    "patch_size = 16\n",
    "patches = rearrange(x, 'b c (h s1) (w s2) -> b (h w) (s1 s2 c)', \n",
    "                    s1=patch_size, s2=patch_size)\n",
    "print(f\"patches: {patches.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 768, 14, 14]         590,592\n",
      "         Rearrange-2             [-1, 196, 768]               0\n",
      "================================================================\n",
      "Total params: 590,592\n",
      "Trainable params: 590,592\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 2.30\n",
      "Params size (MB): 2.25\n",
      "Estimated Total Size (MB): 5.12\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "patch_size = 16\n",
    "in_channels = 3\n",
    "emb_size = 768 # channel * patch_size * patch_size\n",
    "\n",
    "projection = nn.Sequential(\n",
    "    nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size), \n",
    "    Rearrange('b e (h) (w) -> b (h w) e')\n",
    ")\n",
    "summary(projection, x.shape[1:], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
